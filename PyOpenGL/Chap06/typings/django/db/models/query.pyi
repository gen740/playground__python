"""
This type stub file was generated by pyright.
"""

from django.utils.functional import cached_property

"""
The main QuerySet implementation. This provides the public API for the ORM.
"""
MAX_GET_RESULTS = ...
REPR_OUTPUT_SIZE = ...
class BaseIterable:
    def __init__(self, queryset, chunked_fetch=..., chunk_size=...) -> None:
        ...
    


class ModelIterable(BaseIterable):
    """Iterable that yields a model instance for each row."""
    def __iter__(self):
        ...
    


class ValuesIterable(BaseIterable):
    """
    Iterable returned by QuerySet.values() that yields a dict for each row.
    """
    def __iter__(self):
        ...
    


class ValuesListIterable(BaseIterable):
    """
    Iterable returned by QuerySet.values_list(flat=False) that yields a tuple
    for each row.
    """
    def __iter__(self):
        ...
    


class NamedValuesListIterable(ValuesListIterable):
    """
    Iterable returned by QuerySet.values_list(named=True) that yields a
    namedtuple for each row.
    """
    def __iter__(self):
        ...
    


class FlatValuesListIterable(BaseIterable):
    """
    Iterable returned by QuerySet.values_list(flat=True) that yields single
    values.
    """
    def __iter__(self):
        ...
    


class QuerySet:
    """Represent a lazy database lookup for a set of objects."""
    def __init__(self, model=..., query=..., using=..., hints=...) -> None:
        ...
    
    @property
    def query(self):
        ...
    
    @query.setter
    def query(self, value):
        ...
    
    def as_manager(cls):
        ...
    
    as_manager = ...
    def __deepcopy__(self, memo):
        """Don't populate the QuerySet's cache."""
        ...
    
    def __getstate__(self):
        ...
    
    def __setstate__(self, state):
        ...
    
    def __repr__(self):
        ...
    
    def __len__(self):
        ...
    
    def __iter__(self):
        """
        The queryset iterator protocol uses three nested iterators in the
        default case:
            1. sql.compiler.execute_sql()
               - Returns 100 rows at time (constants.GET_ITERATOR_CHUNK_SIZE)
                 using cursor.fetchmany(). This part is responsible for
                 doing some column masking, and returning the rows in chunks.
            2. sql.compiler.results_iter()
               - Returns one row at time. At this point the rows are still just
                 tuples. In some cases the return values are converted to
                 Python values at this location.
            3. self.iterator()
               - Responsible for turning the rows into model objects.
        """
        ...
    
    def __bool__(self):
        ...
    
    def __getitem__(self, k):
        """Retrieve an item or slice from the set of results."""
        ...
    
    def __class_getitem__(cls, *args, **kwargs):
        ...
    
    def __and__(self, other):
        ...
    
    def __or__(self, other):
        ...
    
    def iterator(self, chunk_size=...):
        """
        An iterator over the results from applying this QuerySet to the
        database.
        """
        ...
    
    def aggregate(self, *args, **kwargs):
        """
        Return a dictionary containing the calculations (aggregation)
        over the current queryset.

        If args is present the expression is passed as a kwarg using
        the Aggregate object's default alias.
        """
        ...
    
    def count(self):
        """
        Perform a SELECT COUNT() and return the number of records as an
        integer.

        If the QuerySet is already fully cached, return the length of the
        cached results set to avoid multiple SELECT COUNT(*) calls.
        """
        ...
    
    def get(self, *args, **kwargs):
        """
        Perform the query and return a single object matching the given
        keyword arguments.
        """
        ...
    
    def create(self, **kwargs):
        """
        Create a new object with the given kwargs, saving it to the database
        and returning the created object.
        """
        ...
    
    def bulk_create(self, objs, batch_size=..., ignore_conflicts=...):
        """
        Insert each of the instances into the database. Do *not* call
        save() on each of the instances, do not send any pre/post_save
        signals, and do not set the primary key attribute if it is an
        autoincrement field (except if features.can_return_rows_from_bulk_insert=True).
        Multi-table models are not supported.
        """
        ...
    
    def bulk_update(self, objs, fields, batch_size=...):
        """
        Update the given fields in each of the given objects in the database.
        """
        ...
    
    def get_or_create(self, defaults=..., **kwargs):
        """
        Look up an object with the given kwargs, creating one if necessary.
        Return a tuple of (object, created), where created is a boolean
        specifying whether an object was created.
        """
        ...
    
    def update_or_create(self, defaults=..., **kwargs):
        """
        Look up an object with the given kwargs, updating one with defaults
        if it exists, otherwise create a new one.
        Return a tuple (object, created), where created is a boolean
        specifying whether an object was created.
        """
        ...
    
    def earliest(self, *fields):
        ...
    
    def latest(self, *fields):
        ...
    
    def first(self):
        """Return the first object of a query or None if no match is found."""
        ...
    
    def last(self):
        """Return the last object of a query or None if no match is found."""
        ...
    
    def in_bulk(self, id_list=..., *, field_name=...):
        """
        Return a dictionary mapping each of the given IDs to the object with
        that ID. If `id_list` isn't provided, evaluate the entire QuerySet.
        """
        ...
    
    def delete(self):
        """Delete the records in the current QuerySet."""
        ...
    
    def update(self, **kwargs):
        """
        Update all elements in the current QuerySet, setting all the given
        fields to the appropriate values.
        """
        ...
    
    def exists(self):
        ...
    
    def explain(self, *, format=..., **options):
        ...
    
    def raw(self, raw_query, params=..., translations=..., using=...):
        ...
    
    def values(self, *fields, **expressions):
        ...
    
    def values_list(self, *fields, flat=..., named=...):
        ...
    
    def dates(self, field_name, kind, order=...):
        """
        Return a list of date objects representing all available dates for
        the given field_name, scoped to 'kind'.
        """
        ...
    
    def datetimes(self, field_name, kind, order=..., tzinfo=..., is_dst=...):
        """
        Return a list of datetime objects representing all available
        datetimes for the given field_name, scoped to 'kind'.
        """
        ...
    
    def none(self):
        """Return an empty QuerySet."""
        ...
    
    def all(self):
        """
        Return a new QuerySet that is a copy of the current one. This allows a
        QuerySet to proxy for a model manager in some cases.
        """
        ...
    
    def filter(self, *args, **kwargs):
        """
        Return a new QuerySet instance with the args ANDed to the existing
        set.
        """
        ...
    
    def exclude(self, *args, **kwargs):
        """
        Return a new QuerySet instance with NOT (args) ANDed to the existing
        set.
        """
        ...
    
    def complex_filter(self, filter_obj):
        """
        Return a new QuerySet instance with filter_obj added to the filters.

        filter_obj can be a Q object or a dictionary of keyword lookup
        arguments.

        This exists to support framework features such as 'limit_choices_to',
        and usually it will be more natural to use other methods.
        """
        ...
    
    def union(self, *other_qs, all=...):
        ...
    
    def intersection(self, *other_qs):
        ...
    
    def difference(self, *other_qs):
        ...
    
    def select_for_update(self, nowait=..., skip_locked=..., of=..., no_key=...):
        """
        Return a new QuerySet instance that will select objects with a
        FOR UPDATE lock.
        """
        ...
    
    def select_related(self, *fields):
        """
        Return a new QuerySet instance that will select related objects.

        If fields are specified, they must be ForeignKey fields and only those
        related objects are included in the selection.

        If select_related(None) is called, clear the list.
        """
        ...
    
    def prefetch_related(self, *lookups):
        """
        Return a new QuerySet instance that will prefetch the specified
        Many-To-One and Many-To-Many related objects when the QuerySet is
        evaluated.

        When prefetch_related() is called more than once, append to the list of
        prefetch lookups. If prefetch_related(None) is called, clear the list.
        """
        ...
    
    def annotate(self, *args, **kwargs):
        """
        Return a query set in which the returned objects have been annotated
        with extra data or aggregations.
        """
        ...
    
    def alias(self, *args, **kwargs):
        """
        Return a query set with added aliases for extra data or aggregations.
        """
        ...
    
    def order_by(self, *field_names):
        """Return a new QuerySet instance with the ordering changed."""
        ...
    
    def distinct(self, *field_names):
        """
        Return a new QuerySet instance that will select only distinct results.
        """
        ...
    
    def extra(self, select=..., where=..., params=..., tables=..., order_by=..., select_params=...):
        """Add extra SQL fragments to the query."""
        ...
    
    def reverse(self):
        """Reverse the ordering of the QuerySet."""
        ...
    
    def defer(self, *fields):
        """
        Defer the loading of data for certain fields until they are accessed.
        Add the set of deferred fields to any existing set of deferred fields.
        The only exception to this is if None is passed in as the only
        parameter, in which case removal all deferrals.
        """
        ...
    
    def only(self, *fields):
        """
        Essentially, the opposite of defer(). Only the fields passed into this
        method and that are not already specified as deferred are loaded
        immediately when the queryset is evaluated.
        """
        ...
    
    def using(self, alias):
        """Select which database this QuerySet should execute against."""
        ...
    
    @property
    def ordered(self):
        """
        Return True if the QuerySet is ordered -- i.e. has an order_by()
        clause or a default ordering on the model (or is empty).
        """
        ...
    
    @property
    def db(self):
        """Return the database used if this query is executed now."""
        ...
    
    def resolve_expression(self, *args, **kwargs):
        ...
    


class InstanceCheckMeta(type):
    def __instancecheck__(self, instance):
        ...
    


class EmptyQuerySet(metaclass=InstanceCheckMeta):
    """
    Marker class to checking if a queryset is empty by .none():
        isinstance(qs.none(), EmptyQuerySet) -> True
    """
    def __init__(self, *args, **kwargs) -> None:
        ...
    


class RawQuerySet:
    """
    Provide an iterator which converts the results of raw SQL queries into
    annotated model instances.
    """
    def __init__(self, raw_query, model=..., query=..., params=..., translations=..., using=..., hints=...) -> None:
        ...
    
    def resolve_model_init_order(self):
        """Resolve the init field names and value positions."""
        ...
    
    def prefetch_related(self, *lookups):
        """Same as QuerySet.prefetch_related()"""
        ...
    
    def __len__(self):
        ...
    
    def __bool__(self):
        ...
    
    def __iter__(self):
        ...
    
    def iterator(self):
        ...
    
    def __repr__(self):
        ...
    
    def __getitem__(self, k):
        ...
    
    @property
    def db(self):
        """Return the database used if this query is executed now."""
        ...
    
    def using(self, alias):
        """Select the database this RawQuerySet should execute against."""
        ...
    
    @cached_property
    def columns(self):
        """
        A list of model field names in the order they'll appear in the
        query results.
        """
        ...
    
    @cached_property
    def model_fields(self):
        """A dict mapping column names to model field names."""
        ...
    


class Prefetch:
    def __init__(self, lookup, queryset=..., to_attr=...) -> None:
        ...
    
    def __getstate__(self):
        ...
    
    def add_prefix(self, prefix):
        ...
    
    def get_current_prefetch_to(self, level):
        ...
    
    def get_current_to_attr(self, level):
        ...
    
    def get_current_queryset(self, level):
        ...
    
    def __eq__(self, other) -> bool:
        ...
    
    def __hash__(self) -> int:
        ...
    


def normalize_prefetch_lookups(lookups, prefix=...):
    """Normalize lookups into Prefetch objects."""
    ...

def prefetch_related_objects(model_instances, *related_lookups):
    """
    Populate prefetched object caches for a list of model instances based on
    the lookups/Prefetch instances given.
    """
    ...

def get_prefetcher(instance, through_attr, to_attr):
    """
    For the attribute 'through_attr' on the given instance, find
    an object that has a get_prefetch_queryset().
    Return a 4 tuple containing:
    (the object with get_prefetch_queryset (or None),
     the descriptor object representing this relationship (or None),
     a boolean that is False if the attribute was not found at all,
     a function that takes an instance and returns a boolean that is True if
     the attribute has already been fetched for that instance)
    """
    ...

def prefetch_one_level(instances, prefetcher, lookup, level):
    """
    Helper function for prefetch_related_objects().

    Run prefetches on all instances using the prefetcher object,
    assigning results to relevant caches in instance.

    Return the prefetched objects along with any additional prefetches that
    must be done due to prefetch_related lookups found from default managers.
    """
    ...

class RelatedPopulator:
    """
    RelatedPopulator is used for select_related() object instantiation.

    The idea is that each select_related() model will be populated by a
    different RelatedPopulator instance. The RelatedPopulator instances get
    klass_info and select (computed in SQLCompiler) plus the used db as
    input for initialization. That data is used to compute which columns
    to use, how to instantiate the model, and how to populate the links
    between the objects.

    The actual creation of the objects is done in populate() method. This
    method gets row and from_obj as input and populates the select_related()
    model instance.
    """
    def __init__(self, klass_info, select, db) -> None:
        ...
    
    def populate(self, row, from_obj):
        ...
    


def get_related_populators(klass_info, select, db):
    ...

